ARG BASE_IMAGE=nvcr.io/nvidia/l4t-base:r32.6.1
FROM ${BASE_IMAGE}

ARG NUM_JOBS=4
ARG ONNXRUNTIME_VERSION=1.9.1
ARG CMAKE_VERSION=3.21.1

ARG ROS_PKG=ros_base
ENV ROS_DISTRO=foxy
ENV ROS_ROOT=/opt/ros/${ROS_DISTRO}
RUN mkdir wheels
ARG WHEEL_FILE=/wheels/onnxruntime_gpu-1.8.0-cp36-cp36m-linux_aarch64.whl
ADD https://nvidia.box.com/shared/static/bfs688apyvor4eo8sf3y1oqtnarwafww.whl ${WHEEL_FILE}
RUN echo "Building ONNX Runtime Docker image with ${WHEEL_FILE}..."

# Ensure apt-get won't prompt for selecting options
ENV DEBIAN_FRONTEND=noninteractive
ENV SHELL /bin/bash
SHELL ["/bin/bash", "-c"] 

# change the locale from POSIX to UTF-8
RUN locale-gen en_US en_US.UTF-8 && update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8
ENV LANG=en_US.UTF-8
ENV PYTHONIOENCODING=utf-8

RUN apt update && \
    apt install -y --no-install-recommends \
    	build-essential \
	    software-properties-common \
        pkg-config \
        ca-certificates \
        wget \
        git \
        curl \
        gnupg2 \
        lsb-release \
	    libopenblas-dev \
        libpython3.6-dev \
        python3-pip \
        python3-dev \
        cmake \
        unattended-upgrades
#RUN unattended-upgrade
RUN pip3 install --upgrade pip
RUN pip3 install setuptools
RUN pip3 install wheel pybind11 pytest

# Install CMake
RUN cd /tmp && \
    wget https://github.com/Kitware/CMake/releases/download/v${CMAKE_VERSION}/cmake-${CMAKE_VERSION}-linux-aarch64.sh && \
    bash cmake-${CMAKE_VERSION}-linux-aarch64.sh --prefix=/usr/local --exclude-subdir --skip-license
RUN rm -rf /tmp/*

# ROS2: follows https://github.com/dusty-nv/jetson-containers/blob/master/Dockerfile.ros.foxy
RUN curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg
RUN echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(lsb_release -cs) main" | tee /etc/apt/sources.list.d/ros2.list > /dev/null

RUN apt update && \
    apt install -y \
        python3-colcon-common-extensions \
        python3-flake8 \
        python3-numpy \
        python3-pytest-cov \
		python3-rosdep \
		python3-setuptools \
		python3-vcstool \
		python3-rosinstall-generator \
        libasio-dev \
		libtinyxml2-dev \
		libcunit1-dev \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

RUN python3 -m pip install -U \
		argcomplete \
		flake8-blind-except \
		flake8-builtins \
		flake8-class-newline \
		flake8-comprehensions \
		flake8-deprecated \
		flake8-docstrings \
		flake8-import-order \
		flake8-quotes \
		pytest-repeat \
		pytest-rerunfailures \
		pytest

# yaml-cpp, which some ROS packages may use (but is not in the 18.04 apt repo)
RUN git clone --branch yaml-cpp-0.6.0 https://github.com/jbeder/yaml-cpp yaml-cpp-0.6 && \
    cd yaml-cpp-0.6 && \
    mkdir build && \
    cd build && \
    cmake -DBUILD_SHARED_LIBS=ON .. && \
    make -j${NUM_JOBS} && \
    cp libyaml-cpp.so.0.6.0 /usr/lib/aarch64-linux-gnu/ && \
    ln -s /usr/lib/aarch64-linux-gnu/libyaml-cpp.so.0.6.0 /usr/lib/aarch64-linux-gnu/libyaml-cpp.so.0.6

RUN mkdir -p ${ROS_ROOT}/src && \
    cd ${ROS_ROOT} && \
    # https://answers.ros.org/question/325245/minimal-ros2-installation/?answer=325249#post-id-325249
    rosinstall_generator --deps --rosdistro ${ROS_DISTRO} ${ROS_PKG} \
		launch_xml \
		launch_yaml \
		launch_testing \
		launch_testing_ament_cmake \
		#demo_nodes_cpp \
		#demo_nodes_py \
		#example_interfaces \
		#camera_calibration_parsers \
		#camera_info_manager \
		#cv_bridge \
		#v4l2_camera \
		#vision_opencv \
		#vision_msgs \
		#image_geometry \
		#image_pipeline \
		#image_transport \
		#compressed_image_transport \
		#compressed_depth_image_transport \
		> ros2.${ROS_DISTRO}.${ROS_PKG}.rosinstall && \
    cat ros2.${ROS_DISTRO}.${ROS_PKG}.rosinstall && \
    vcs import src < ros2.${ROS_DISTRO}.${ROS_PKG}.rosinstall && \
    # patch libyaml - https://github.com/dusty-nv/jetson-containers/issues/41#issuecomment-774767272
    rm ${ROS_ROOT}/src/libyaml_vendor/CMakeLists.txt && \
    wget --no-check-certificate https://raw.githubusercontent.com/ros2/libyaml_vendor/master/CMakeLists.txt -P ${ROS_ROOT}/src/libyaml_vendor/ && \
    # install dependencies using rosdep
    apt-get update && \
    cd ${ROS_ROOT} && \
    rosdep init && \
    rosdep update && \
    rosdep install -y \
    	  --ignore-src \
       --from-paths src \
	  --rosdistro ${ROS_DISTRO} \
	  --skip-keys "libopencv-dev libopencv-contrib-dev libopencv-imgproc-dev python-opencv python3-opencv" && \
    rm -rf /var/lib/apt/lists/* && \
    apt-get clean && \
    # build it!
    colcon build --merge-install && \
    # remove build files
    rm -rf ${ROS_ROOT}/src && \
    rm -rf ${ROS_ROOT}/logs && \
    rm -rf ${ROS_ROOT}/build && \
    rm ${ROS_ROOT}/*.rosinstall

# Set the default DDS middleware to cyclonedds
# https://github.com/ros2/rclcpp/issues/1335
ENV RMW_IMPLEMENTATION=rmw_cyclonedds_cpp

# setup entrypoint
COPY ./scripts/ros_entrypoint.sh /ros_entrypoint.sh
RUN sed -i \
    's/ros_env_setup="\/opt\/ros\/$ROS_DISTRO\/setup.bash"/ros_env_setup="${ROS_ROOT}\/install\/setup.bash"/g' \
    /ros_entrypoint.sh && \
    cat /ros_entrypoint.sh
RUN echo 'source ${ROS_ROOT}/install/setup.bash' >> /root/.bashrc

# Install ONNX Runtime
# ENV PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}
# ENV CUDACXX=/usr/local/cuda/bin/nvcc

# RUN ln -s /usr/local/cuda/lib64/libcudadevrt.so /usr/local/cuda-10.2/targets/aarch64-linux/lib/stubs/libcudadevrt.so
# RUN ln -s /usr/local/cuda/lib64/libcudart.so /usr/local/cuda-10.2/targets/aarch64-linux/lib/stubs/libcudart.so
# RUN ln -s /usr/local/cuda/lib64/libcudart.so /usr/local/cuda-10.2/targets/aarch64-linux/lib/libcudart.so
# RUN ln -s /usr/local/cuda/lib64/libcudadevrt.so /usr/local/cuda-10.2/targets/aarch64-linux/lib/libcudadevrt.so
# RUN nvcc --version
RUN cd /tmp && \
    git clone --recursive --single-branch --branch v${ONNXRUNTIME_VERSION} https://github.com/Microsoft/onnxruntime

# RUN ln -s /usr/local/cuda/lib64/libcudadevrt.a /usr/local/cuda-10.2/targets/aarch64-linux/lib/stubs/libcudadevrt.a
# RUN ln -s /usr/local/cuda/lib64/libcudart_static.a /usr/local/cuda-10.2/targets/aarch64-linux/lib/stubs/libcudart_static.a
# RUN ln -s /usr/local/cuda/lib64/libcudart_static.a /usr/local/cuda-10.2/targets/aarch64-linux/lib/libcudart_static.a
# RUN ln -s /usr/local/cuda/lib64/libcudadevrt.a /usr/local/cuda-10.2/targets/aarch64-linux/lib/libcudadevrt.a
#ENV LIBRARY_PATH $LIBRARY_PATH:/usr/local/cuda/lib64/stubs
RUN cd /tmp/onnxruntime && \
    ./build.sh \
        --use_cuda \
        --cuda_home /usr/local/cuda-10.2 \
        --cudnn_home /usr/lib/aarch64-linux-gnu \
        --use_tensorrt \
        --tensorrt_home /usr/lib/aarch64-linux-gnu \
        --config RelWithDebInfo \
        --build_shared_lib \
        --build \
        --build_wheel \
        --update \
        --skip_submodule_sync \
        --skip_tests \
        --arm64 \
        --parallel ${NUM_JOBS} \
        --cmake_extra_defines ONNXRUNTIME_VERSION=${ONNXRUNTIME_VERSION} CMAKE_CUDA_ARCHITECTURES=53 && \
    cd build/Linux/RelWithDebInfo && \
    make install && \
    python3 -m pip install dist/*.whl
RUN rm -rf /tmp/*

ENTRYPOINT ["/ros_entrypoint.sh"]
CMD ["bash"]
WORKDIR /